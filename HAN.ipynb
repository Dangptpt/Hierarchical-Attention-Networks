{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sslYE2KcIRQU"
      },
      "source": [
        "Download pretrained model embedding Glove\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YE_K0QOmFY9i",
        "outputId": "40761b9f-1115-45a6-aacf-90ceb4bb2f06"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.11.3)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'e:/Study/NLP/HAN/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cttvFYCPGg75",
        "outputId": "90b2a6bb-b085-4adc-f713-340c0d5977e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-04-11 03:59:19--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2024-04-11 03:59:19--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2024-04-11 03:59:20--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.14MB/s    in 2m 42s  \n",
            "\n",
            "2024-04-11 04:02:03 (5.06 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNYC3VSUIP6k"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0dgJcfNGnmP",
        "outputId": "91c5c0fe-4726-4fa3-a64e-5fe87a139b45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ],
      "source": [
        "!unzip glove*.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXYgruKFH7Af",
        "outputId": "130ebc4e-72f4-44e2-857b-c68f3e25ee8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdata\u001b[0m/              glove.6B.200d.txt  glove.6B.50d.txt  \u001b[01;34msample_data\u001b[0m/\n",
            "glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EE5uQ_aHIAYr",
        "outputId": "1f652362-b475-4e0d-b1ce-99ce0bf4295b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-85b6fe2dabac>:4: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
            "  glove2word2vec(glove_input_file, word2vec_output_file)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(400000, 100)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "glove_input_file = 'glove.6B.100d.txt'\n",
        "word2vec_output_file = 'word2vec.txt'\n",
        "glove2word2vec(glove_input_file, word2vec_output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wd7YYmobIffx",
        "outputId": "042ac5f8-4731-4b09-d06f-2f3c6a08ba38"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 399999/400000 [00:27<00:00, 14612.97it/s]\n"
          ]
        }
      ],
      "source": [
        "from torchtext import vocab\n",
        "word2vec = vocab.Vectors('glove.6B.100d.txt', 'train/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bljp027sJdyO",
        "outputId": "58fc8407-e7e3-44ae-8158-e80eed414a93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(word2vec['king'].shape)\n",
        "word2vec['<pad>']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSrGCSn9SAID",
        "outputId": "a5f2219b-650b-42eb-a3a8-0ecc91b073f6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbQp6DkZI90i"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import csv\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0M3aL_vNJLiQ"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data_dir, max_length_word=50, max_length_sentences=16, transform=None, target_transform=None):\n",
        "        super(CustomDataset, self).__init__()\n",
        "\n",
        "        self.data_dir = data_dir\n",
        "        self.max_length_sentences = max_length_sentences\n",
        "        self.max_length_word = max_length_word\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "        text_list, label_list = [], []\n",
        "        with open(data_dir) as csv_file:\n",
        "            reader = csv.reader(csv_file, quotechar='\"')\n",
        "            for idx, line in enumerate(reader):\n",
        "                if idx == 0:\n",
        "                    continue\n",
        "                text = \"\"\n",
        "                for tx in line[1:]:\n",
        "                    text += tx.lower()\n",
        "                    text += \". \"\n",
        "                label = int(line[0])-1\n",
        "                text_list.append(text)\n",
        "                label_list.append(label)\n",
        "\n",
        "        self.label_list = label_list\n",
        "        self.text_list = text_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label_list)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.label_list[index]\n",
        "        text = self.text_list[index]\n",
        "        document_encode = [[word2vec[word] for word in word_tokenize(sentences)]\n",
        "                           for sentences in sent_tokenize(text)]\n",
        "\n",
        "        for sentences in document_encode:\n",
        "            if len(sentences) < self.max_length_word:\n",
        "                extended_words = [word2vec['<pad>'].numpy() for _ in range(self.max_length_word - len(sentences))]\n",
        "                sentences.extend(extended_words)\n",
        "\n",
        "        if len(document_encode) < self.max_length_sentences:\n",
        "            extended_sentences = [[word2vec['<pad>'].numpy() for _ in range(self.max_length_word)] for _ in\n",
        "                                  range(self.max_length_sentences - len(document_encode))]\n",
        "            document_encode.extend(extended_sentences)\n",
        "\n",
        "        document_encode = [sentences[:self.max_length_word] for sentences in document_encode][\n",
        "                          :self.max_length_sentences]\n",
        "\n",
        "        document_encode = np.stack(arrays=document_encode, axis=0)\n",
        "        if self.transform:\n",
        "            document_encode = self.transform(document_encode)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        return document_encode, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmAXsLzyXWd_",
        "outputId": "3151d027-f549-433b-b037-faa0bccca345"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7600\n"
          ]
        }
      ],
      "source": [
        "texts, labels = [], []\n",
        "data_path=\"/content/data/test.csv\"\n",
        "with open(data_path) as csv_file:\n",
        "    reader = csv.reader(csv_file, quotechar='\"')\n",
        "    for idx, line in enumerate(reader):\n",
        "        if idx == 0:\n",
        "            continue\n",
        "        text = \"\"\n",
        "        for tx in line[1:]:\n",
        "            text += tx.lower()\n",
        "            text += \". \"\n",
        "        label = int(line[0])\n",
        "        texts.append(text)\n",
        "        labels.append(label)\n",
        "\n",
        "n = len(labels)\n",
        "print (n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quqI-Dcpqfss",
        "outputId": "e2858c2f-f1c5-4160-fa4c-80062a93bf25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "938\n",
            "torch.Size([128, 4])\n"
          ]
        }
      ],
      "source": [
        "from torchtext.functional import to_tensor\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "\n",
        "training_data = CustomDataset(data_dir=\"/content/data/train.csv\",\n",
        "                              transform = torch.tensor,\n",
        "                              target_transform=Lambda(lambda y: torch.zeros(4, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
        ")\n",
        "test_data = CustomDataset(data_dir=\"/content/data/test.csv\",\n",
        "                          transform = torch.tensor,\n",
        "                          target_transform=Lambda(lambda y: torch.zeros(4, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=128, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=128, shuffle=True)\n",
        "\n",
        "print(len(train_dataloader))\n",
        "for batch in test_dataloader:\n",
        "    print((batch[1]).shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5kRN-8ozpqa"
      },
      "outputs": [],
      "source": [
        "class SentAttNet(nn.Module):\n",
        "    def __init__(self,  hidden_size=50):\n",
        "        super(SentAttNet, self).__init__()\n",
        "        self.sent_weight = nn.Parameter(torch.Tensor(2 * hidden_size, 10))\n",
        "        self.sent_bias = nn.Parameter(torch.Tensor(10))\n",
        "        self.context_weight = nn.Parameter(torch.Tensor(10, 1))\n",
        "        self.gru = nn.GRU(100, hidden_size, bidirectional=True)\n",
        "        self._create_weights(mean=0.0, std=0.05)\n",
        "\n",
        "    def _create_weights(self, mean=0.0, std=0.05):\n",
        "        self.sent_weight.data.normal_(mean, std)\n",
        "        self.context_weight.data.normal_(mean, std)\n",
        "\n",
        "    def forward(self, input, hidden_state):\n",
        "        f_output, h_output = self.gru(input, hidden_state)\n",
        "        output = matrix_mul(f_output, self.sent_weight, self.context_weight, self.sent_bias)\n",
        "        output = F.softmax(output)\n",
        "        output = element_wise_mul(output.permute(1,0,2), f_output.permute(1,0,2))\n",
        "\n",
        "        return output, h_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duNSxKlQz3bh"
      },
      "outputs": [],
      "source": [
        "class WordAttNet(nn.Module):\n",
        "    def __init__(self,  hidden_size=50):\n",
        "        super(WordAttNet, self).__init__()\n",
        "        self.word_weight = nn.Parameter(torch.Tensor(2 * hidden_size, 10))\n",
        "        self.word_bias = nn.Parameter(torch.Tensor(10))\n",
        "        self.context_weight = nn.Parameter(torch.Tensor(10, 1))\n",
        "        self.gru = nn.GRU(100, hidden_size, bidirectional=True)\n",
        "        self._create_weights(mean=0.0, std=0.05)\n",
        "\n",
        "    def _create_weights(self, mean=0.0, std=0.05):\n",
        "        self.word_weight.data.normal_(mean, std)\n",
        "        self.context_weight.data.normal_(mean, std)\n",
        "\n",
        "    def forward(self, input, hidden_state):\n",
        "        f_output, h_output = self.gru(input, hidden_state)\n",
        "        output = matrix_mul(f_output, self.word_weight, self.context_weight, self.word_bias)\n",
        "        output = F.softmax(output)\n",
        "        output = element_wise_mul(output.permute(1,0,2), f_output.permute(1,0,2))\n",
        "        return output, h_output\n",
        "\n",
        "def element_wise_mul(input1, input2):\n",
        "    feature_list = []\n",
        "    for feature_1, feature_2 in zip(input1, input2):\n",
        "        feature = (feature_1 * feature_2).sum(dim=0)\n",
        "        feature_list.append(feature)\n",
        "\n",
        "    output = torch.stack(feature_list, dim=0)\n",
        "    return output\n",
        "\n",
        "def matrix_mul(input, weight, context_weight,  bias=False):\n",
        "    input = torch.matmul(input, weight)\n",
        "    input = input + bias\n",
        "    input = torch.tanh(input)\n",
        "    input = torch.matmul(input, context_weight)\n",
        "\n",
        "    return input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lZ5EdDFz7VI"
      },
      "outputs": [],
      "source": [
        "class HierAttNet(nn.Module):\n",
        "    def __init__(self, word_hidden_size=50, sent_hidden_size=50, batch_size=128, num_classes=4, max_sent_length=16, max_word_length=50):\n",
        "        super(HierAttNet, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.word_hidden_size = word_hidden_size\n",
        "        self.sent_hidden_size = sent_hidden_size\n",
        "        self.max_sent_length = max_sent_length\n",
        "        self.max_word_length = max_word_length\n",
        "        self.word_att_net = WordAttNet(word_hidden_size)\n",
        "        self.sent_att_net = SentAttNet(sent_hidden_size)\n",
        "        self._init_hidden_state()\n",
        "        self.dense = torch.nn.Linear(sent_hidden_size*2, num_classes, bias=True)\n",
        "\n",
        "    def _init_hidden_state(self, last_batch_size=None):\n",
        "        if last_batch_size:\n",
        "            batch_size = last_batch_size\n",
        "        else:\n",
        "            batch_size = self.batch_size\n",
        "        self.word_hidden_state = torch.zeros(2, batch_size, self.word_hidden_size)\n",
        "        self.sent_hidden_state = torch.zeros(2, batch_size, self.sent_hidden_size)\n",
        "        if torch.cuda.is_available():\n",
        "            self.word_hidden_state = self.word_hidden_state.cuda()\n",
        "            self.sent_hidden_state = self.sent_hidden_state.cuda()\n",
        "\n",
        "    def forward(self, input):\n",
        "        output_list = []\n",
        "        input = input.permute(1, 0, 2, 3)\n",
        "        for seq in input:\n",
        "            output, self.word_hidden_state = self.word_att_net(seq.permute(1, 0, 2), self.word_hidden_state)\n",
        "            output_list.append(output)\n",
        "\n",
        "        output = torch.stack(output_list, dim=0)\n",
        "        output, self.sent_hidden_state = self.sent_att_net(output, self.sent_hidden_state)\n",
        "        output = self.dense(output)\n",
        "        output = F.softmax(output,dim=1)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhJhQ-uI_GBP",
        "outputId": "77ad8015-f709-4358-9195-5c80c21771db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HierAttNet(\n",
            "  (word_att_net): WordAttNet(\n",
            "    (gru): GRU(100, 50, bidirectional=True)\n",
            "  )\n",
            "  (sent_att_net): SentAttNet(\n",
            "    (gru): GRU(100, 50, bidirectional=True)\n",
            "  )\n",
            "  (dense): Linear(in_features=100, out_features=4, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = HierAttNet()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2HmE1on_ayf"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKkFrjP-_Zqc"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_loop(model, dataloader, optimizer, loss_fn, epoch_num):\n",
        "    size = len(dataloader)\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    model.train()\n",
        "    model.zero_grad()\n",
        "\n",
        "    for batch in tqdm(dataloader, f\"Epoch: {epoch_num}\"):\n",
        "        batch = [t.to(device='cuda') for t in batch]\n",
        "        if batch[1].shape[0] < 128:\n",
        "              model._init_hidden_state(last_batch_size = batch[1].shape[0])\n",
        "        else:\n",
        "              model._init_hidden_state()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        pred = model(batch[0])\n",
        "        loss = loss_fn(pred, batch[1])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        pred_classes = torch.zeros_like(pred)\n",
        "        pred_classes[torch.arange(len(pred)), torch.argmax(pred, dim=1)] = 1\n",
        "        correct_preds = (pred_classes * batch[1]).float()\n",
        "\n",
        "        correct += (correct_preds.sum()/len(correct_preds)).item()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        time.sleep(0.001) # for tqdm progess bar\n",
        "\n",
        "    print(f\"\\nTrain Error:\\t Accuracy: {(100*correct/size):>0.1f}%, Avg loss: {total_loss/size:>8f} \\n\")\n",
        "\n",
        "\n",
        "def test_loop(model, dataloader, loss_fn, epoch_num):\n",
        "    size = len(dataloader)\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            batch = [t.to(device='cuda') for t in batch]\n",
        "            if batch[1].shape[0] < 128:\n",
        "                model._init_hidden_state(last_batch_size = batch[1].shape[0])\n",
        "            else:\n",
        "                model._init_hidden_state()\n",
        "\n",
        "            pred = model(batch[0])\n",
        "            loss = loss_fn(pred, batch[1])\n",
        "\n",
        "            pred_classes = torch.zeros_like(pred)\n",
        "            pred_classes[torch.arange(len(pred)), torch.argmax(pred, dim=1)] = 1\n",
        "            correct_preds = (pred_classes * batch[1]).float()\n",
        "\n",
        "            correct += (correct_preds.sum()/len(correct_preds)).item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    print(f\"\\tTest Error:\\t Accuracy: {(100*correct/size):>0.1f}%, Avg loss: {total_loss/size:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Vi7q8D9AnS5",
        "outputId": "c1e2cee2-e4d8-4b6b-bbc2-27fdd720dc8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH 1:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 1:   0%|          | 0/938 [00:00<?, ?it/s]<ipython-input-87-f0a3bdbdf28b>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = F.softmax(output)\n",
            "Epoch: 1: 100%|██████████| 938/938 [20:17<00:00,  1.30s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Error:\t Accuracy: 77.5%, Avg loss: 0.974136 \n",
            "\n",
            "\tTest Error:\t Accuracy: 87.5%, Avg loss: 0.867958 \n",
            "\n",
            "EPOCH 2:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 2: 100%|██████████| 938/938 [20:06<00:00,  1.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Error:\t Accuracy: 88.3%, Avg loss: 0.859467 \n",
            "\n",
            "\tTest Error:\t Accuracy: 88.5%, Avg loss: 0.856519 \n",
            "\n",
            "EPOCH 3:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 3: 100%|██████████| 938/938 [20:33<00:00,  1.31s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train Error:\t Accuracy: 89.2%, Avg loss: 0.850084 \n",
            "\n",
            "\tTest Error:\t Accuracy: 88.4%, Avg loss: 0.857591 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = HierAttNet()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "lr = 3e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "model.to(device)\n",
        "\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    print(f'EPOCH {epoch+1}:')\n",
        "    torch.compile(train_loop(model, train_dataloader, optimizer, loss_fn, epoch+1))\n",
        "    test_loop(model, test_dataloader, loss_fn, epoch+1)\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), 'model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sG-4T9WWz9hF",
        "outputId": "293eb62c-05d4-4b46-dfd0-ee57c1eea34e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------------------------+------------+\n",
            "|                Modules                | Parameters |\n",
            "+---------------------------------------+------------+\n",
            "|        word_att_net.word_weight       |    1000    |\n",
            "|         word_att_net.word_bias        |     10     |\n",
            "|      word_att_net.context_weight      |     10     |\n",
            "|     word_att_net.gru.weight_ih_l0     |   15000    |\n",
            "|     word_att_net.gru.weight_hh_l0     |    7500    |\n",
            "|      word_att_net.gru.bias_ih_l0      |    150     |\n",
            "|      word_att_net.gru.bias_hh_l0      |    150     |\n",
            "| word_att_net.gru.weight_ih_l0_reverse |   15000    |\n",
            "| word_att_net.gru.weight_hh_l0_reverse |    7500    |\n",
            "|  word_att_net.gru.bias_ih_l0_reverse  |    150     |\n",
            "|  word_att_net.gru.bias_hh_l0_reverse  |    150     |\n",
            "|        sent_att_net.sent_weight       |    1000    |\n",
            "|         sent_att_net.sent_bias        |     10     |\n",
            "|      sent_att_net.context_weight      |     10     |\n",
            "|     sent_att_net.gru.weight_ih_l0     |   15000    |\n",
            "|     sent_att_net.gru.weight_hh_l0     |    7500    |\n",
            "|      sent_att_net.gru.bias_ih_l0      |    150     |\n",
            "|      sent_att_net.gru.bias_hh_l0      |    150     |\n",
            "| sent_att_net.gru.weight_ih_l0_reverse |   15000    |\n",
            "| sent_att_net.gru.weight_hh_l0_reverse |    7500    |\n",
            "|  sent_att_net.gru.bias_ih_l0_reverse  |    150     |\n",
            "|  sent_att_net.gru.bias_hh_l0_reverse  |    150     |\n",
            "|              dense.weight             |    400     |\n",
            "|               dense.bias              |     4      |\n",
            "+---------------------------------------+------------+\n",
            "Total Trainable Params: 93644\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "93644"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = HierAttNet()\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "def count_parameters(model):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad:\n",
        "            continue\n",
        "        params = parameter.numel()\n",
        "        table.add_row([name, params])\n",
        "        total_params += params\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params\n",
        "\n",
        "count_parameters(model)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
